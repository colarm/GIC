{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cleaning Data - WORKSHOP NOTES.ipynb","provenance":[{"file_id":"1ptGkLwNoNyFAw0ubxsmDY8OqO61NwkGt","timestamp":1574191859113},{"file_id":"1gYE3Gb64a1GtJFdSCtbT8ZKgCyecw17N","timestamp":1567181515365},{"file_id":"1OZRg4rYXxrHVxOhuCaLnr0a1a4arXbJ0","timestamp":1560422987513},{"file_id":"14--7Sqk2BasgM9A3JfgEUHDDShkJUeNI","timestamp":1560417425558},{"file_id":"18Vp28B-7YMjcdeszjEtJQUlWEKIQxdjq","timestamp":1560410473585},{"file_id":"1l_W74rzq1-4KTxnN3LUWUmbIjWBrEvRK","timestamp":1560402405234},{"file_id":"1Gj8xFEghBwX8exDkdBWvNSzOUTYlNxI9","timestamp":1560164255413},{"file_id":"1TeHiJ5s48kWFy5BosIWhjK2MQyMkPHNo","timestamp":1559546187577},{"file_id":"1f_9CXFJzBvrAePaDr_WYQGHEBS5th53b","timestamp":1559541190636}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZvNsvUNNlZbi","colab_type":"text"},"source":["---\n","# Crash Course Python for Data Science - Intro to Pandas \n","---\n","# 03 - Cleaning Data \n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"f7sGhOifhpFD","colab_type":"text"},"source":["### Cleaning data is an *integral part of being a data scientist*  \n","In most contexts, the data you'll be using to generate insights will not be perfect. Far from it. There will be missing values. There will be incorrect values. There could be duplicate values. Columns could have data types that break your code. There could be outliers that mess things up. You may even need to merge data from different sources to do a thorough analysis. Fortunately, pandas has some really powerful methods for cleaning your data. Which is good news, because most data scientists tend to spend the bulk of their time cleaning data before they can analyze it.  \n","\n","*In other words, you clean your data in order to prepare it for analysis and model-building.*"]},{"cell_type":"markdown","metadata":{"id":"veCoTayWYvhi","colab_type":"text"},"source":["### Begin by importing your tools"]},{"cell_type":"code","metadata":{"id":"lwG232gHDwLT","colab_type":"code","colab":{}},"source":["# Let's begin by importing pandas\n","import pandas as pd\n","print('pandas imported!')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oRH-6zIAX6D4","colab_type":"text"},"source":["## Reading in your data"]},{"cell_type":"code","metadata":{"id":"2-4aaacNyNl1","colab_type":"code","colab":{}},"source":["# We use the pandas method pandas.read_csv(\"filepath\") to create a DataFrame \n","# and assign it to a variable:\n","\n","df = pd.read_csv(\"https://raw.githubusercontent.com/axrd/datasets/master/gdpmessy.csv\", index_col=0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TXvBbG-M2BQR","colab_type":"text"},"source":["## Quick inspection of the data"]},{"cell_type":"code","metadata":{"id":"-MqrXh832FYh","colab_type":"code","colab":{}},"source":["# We'll use the head() method, which by default prints out the first 5 rows. I \n","# want to look at the first 10 rows:\n","df.head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYksX9PA6KCm","colab_type":"code","colab":{}},"source":["# Then the tail method. Also for 10 values.\n","df.tail(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"61E6pBkY6NN9","colab_type":"code","colab":{}},"source":["# We're supposed to have 222 observations (rows) and 3 columns. Let's check:\n","\n","df.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JZ2o7IIyuvGI","colab_type":"code","colab":{}},"source":["# A great way to get an overview of our data:\n","df.info()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HUbASLeBwK0e","colab_type":"text"},"source":["**We've got some missing values! We'll address that in a minute. First, let's fix our duplicate index and rename our columns something useful and consistent.**"]},{"cell_type":"markdown","metadata":{"id":"P6nHX2jVwchC","colab_type":"text"},"source":["## Duplicate index\n","**Remember how we dealt with this a few exercises ago, as we were learning about loading data?**\n","\n"]},{"cell_type":"code","metadata":{"id":"3hc56xXy74NF","colab_type":"code","colab":{}},"source":["df.columns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f28mwlOAwjjD","colab_type":"code","colab":{}},"source":["# We need to drop the first column (axis = 1) and do it in place:\n","df.drop('Unnamed: 0', axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8ia9jfvw74T","colab_type":"code","colab":{}},"source":["df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WV_IUNSuwDy9","colab_type":"text"},"source":["## Column names\n","\n","**We also covered how to rename columns. But we only showed you how to rename one at a time:**  \n","\n","\n","*   `COUNRY` should be spelled correctly\n","*   `gdp` is lowercase and should also communicate scale\n","*   `CODE` has an trailing space in it  \n","\n","\n","**Here's how we'd do it one by one:**\n","\n","`df.rename(columns={'COUNRY':'COUNTRY'}, inplace=True)`  \n","`df.rename(columns={'gdp':'GDP (BILLIONS)'}, inplace=True)`  \n","`df.rename(columns={'CODE ':'CODE'}, inplace=True)`\n","\n","**But that's not Pythonic. Let's try and change all of these column names at once.**\n"]},{"cell_type":"code","metadata":{"id":"06chmZrix7ce","colab_type":"code","colab":{}},"source":["# Pandas has a way to select columns because it treats them as an index object:\n","df.columns\n","\n","# Notice that \"CODE \" has an empty space after the last character. This happens!"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejnXwTmZ8Jhf","colab_type":"code","colab":{}},"source":["df['CODE ']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D0OcK-SFyH5F","colab_type":"code","colab":{}},"source":["df.columns = [\"COUNTRY\", \"GDP_BILLIONS\", \"CODE\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQhiyLELy82J","colab_type":"code","colab":{}},"source":["df.columns\n","\n","# Done."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHLGUz35K76Q","colab_type":"code","colab":{}},"source":["list(df.columns)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_SG5LXYK8gLM","colab_type":"code","colab":{}},"source":["df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_mabLSy8nTa","colab_type":"code","colab":{}},"source":["df['GDP_BILLIONS']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X239QCLc1uI5","colab_type":"text"},"source":["## Missing values?\n","We noticed immediately that we had some missing values to deal with. Every feature has at least one missing value (nulls)."]},{"cell_type":"code","metadata":{"id":"RoGSRkP6zxQq","colab_type":"code","colab":{}},"source":["# Pandas has a nifty tool to check for null values. For now, you can think of \n","# nulls as missing values. \n","\n","df.isnull()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ztNrp_ZGvyx6","colab_type":"code","colab":{}},"source":["# Ok, but scrolling throuh 222 rows looking for \"True\" sounds awful. There has \n","# to be a better way, right? There is. Remember the sum function?\n","\n","df.isnull().sum()\n","\n","# Six targets. Let's take them one at a time. Starting with \"Country\"."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hY_khdvO0G7W","colab_type":"code","colab":{}},"source":["# We'll subset our data by choosing ALL the rows that have missing values.\n","\n","df[df.isnull().any(axis=1)]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eez53JH63Fa8","colab_type":"text"},"source":["**Let's say we were able to identify the actual values that belong in the DataFrame as follows:**\n","\n","\n","\n","*   Algeria has an Alpha-3 code of DZA\n","*   Andorra has a GDP of 4.80 billion\n","*   Azerbaijan has an Alpha-3 code of AZE\n","*   Aruba has a GDP of 2.52 billion\n","*   Belize has a GDP of 1.67 billion\n","*   Angola is the missing 'COUNTRY' value  \n","\n","\n","We'll use the pandas [at() method to handle this.](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html)\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"zhbYh4lq4aR3","colab_type":"code","colab":{}},"source":["# We specify the row index, the column name, and the value we'd like to assign to it:\n","df.at[2, \"CODE\"] = \"DZA\"\n","df.at[4, \"GDP_BILLIONS\"] = 4.80\n","df.at[5, \"COUNTRY\"] = \"Angola\"\n","df.at[10, \"GDP_BILLIONS\"] = 2.52\n","df.at[13, \"CODE\"] = \"AZE\"\n","df.at[20, \"GDP_BILLIONS\"] = 1.67"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhXr3OYH5hX5","colab_type":"code","colab":{}},"source":["df.isnull().sum()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-oSMvv8-BlD","colab_type":"code","colab":{}},"source":["df.head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TR0Y4x49XyY4","colab_type":"text"},"source":["## Less obvious things:\n","We checked for missing values, but now we need to worry about duplicate or incorrect values. Let's look for duplicates.  \n","\n","We'll use the `value_counts()` method, sorted to see where any values appear more than once. The `head()` at the end of the chain limits our output to five observations to keep things manageable. If any of them have multiple values beyond the first five observations, we'll expand the head until we account for all duplicates. "]},{"cell_type":"code","metadata":{"id":"2SdLd42Q83w8","colab_type":"code","colab":{}},"source":["df[\"COUNTRY\"].value_counts(sort=True).head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i0VhKP-u9qlO","colab_type":"text"},"source":["That one's good to go. No duplicates (we wouldn't expect any here)."]},{"cell_type":"code","metadata":{"id":"CutlqXqu84W8","colab_type":"code","colab":{}},"source":["df[\"GDP_BILLIONS\"].value_counts(sort=True).head(5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jz0Xio0N9vQg","colab_type":"text"},"source":["Ok. Several duplicates. But we'd expect some in GDP since we're using billions and only two decimal places. In terms of preparing our data, next steps here would be to double-check those values with official records. Alternatively, we could add decimal places for greater precision. "]},{"cell_type":"code","metadata":{"id":"jai2Bb6FsSiI","colab_type":"code","colab":{}},"source":["df[\"CODE\"].value_counts(sort=True).head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w5k7Mlpf-D-C","colab_type":"text"},"source":["This one's dangerous. Like `COUNTRY` we wouldn't expect any duplicate values here, but we've got two. Let's see what's going on:"]},{"cell_type":"code","metadata":{"id":"B04twRrdX_D2","colab_type":"code","colab":{}},"source":["df[df['CODE'] == \"VGB\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D40uNstM-e9V","colab_type":"text"},"source":["So there's the British Virgin Islands and the American Virgin Islands. The latter has an A-3 code of VIR, not VGB. Let's fix it:"]},{"cell_type":"code","metadata":{"id":"_pYartEJ-n0C","colab_type":"code","colab":{}},"source":["df.at[217, \"CODE\"] = \"VIR\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"owclShNA-wAP","colab_type":"code","colab":{}},"source":["df[df['CODE'] == \"HKG\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dQgk8dFS-1OZ","colab_type":"text"},"source":["Hungary is supposed to be HUN. Let's change it: "]},{"cell_type":"code","metadata":{"id":"L16RGE5G-0LH","colab_type":"code","colab":{}},"source":["df.at[90, \"CODE\"] = \"HUN\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X2nqI5Uc_Am_","colab_type":"text"},"source":["To be thorough, let's make sure our changes didn't create any new duplicates in the `CODE` column:"]},{"cell_type":"code","metadata":{"id":"e4KGpNxcYWY4","colab_type":"code","colab":{}},"source":["df[\"CODE\"].value_counts(sort=True).head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7BqbpyNyzxqk","colab_type":"text"},"source":["## Even less obvious things"]},{"cell_type":"code","metadata":{"id":"u49qzTU-_UD7","colab_type":"code","colab":{}},"source":["df.sort_values(by='GDP_BILLIONS', ascending=False).head(10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hd4Oz-QnAGq8","colab_type":"text"},"source":["Clearly, Vanuatu isn't the 3rd largest economy in the world. Its GDP is actually supposed to be 0.82 billion."]},{"cell_type":"code","metadata":{"id":"jnD5BL1VAUOa","colab_type":"code","colab":{}},"source":["df.at[214, \"GDP_BILLIONS\"] = 0.82"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"auBx-PAyRHXJ","colab_type":"code","colab":{}},"source":["df[df['CODE'] == 'BGD']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pNtfYCk-_VBw","colab_type":"text"},"source":["\n","\n","---\n","\n","\n","## That was a lot of new stuff. Remember to practice with the exercise!"]}]}